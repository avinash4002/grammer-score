{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"},{"sourceId":11288705,"sourceType":"datasetVersion","datasetId":7058440}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets torchaudio --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:49:14.389404Z","iopub.execute_input":"2025-04-05T19:49:14.389725Z","iopub.status.idle":"2025-04-05T19:49:20.259370Z","shell.execute_reply.started":"2025-04-05T19:49:14.389689Z","shell.execute_reply":"2025-04-05T19:49:20.258076Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Loaded the whisper model for the trancript generation.\n","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git\n!sudo apt update && sudo apt install -y ffmpeg\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:50:03.922159Z","iopub.execute_input":"2025-04-05T19:50:03.922470Z","iopub.status.idle":"2025-04-05T19:50:31.075837Z","shell.execute_reply.started":"2025-04-05T19:50:03.922448Z","shell.execute_reply":"2025-04-05T19:50:31.074767Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-fcd_ze97\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-fcd_ze97\n  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.9.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\nCollecting triton>=2 (from openai-whisper==20240930)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20240930) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper==20240930) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper==20240930) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper==20240930) (2024.2.0)\nDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=9fd093b9ace15b4634225ee6da13ea4ad7d23e7d45109c57268ff18fd355d518\n  Stored in directory: /tmp/pip-ephem-wheel-cache-e7hzb85t/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\nInstalling collected packages: triton, openai-whisper\nSuccessfully installed openai-whisper-20240930 triton-3.2.0\nGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B][33m\nGet:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \u001b[0m\u001b[33m\nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\nGet:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \u001b[0m\nHit:6 http://archive.ubuntu.com/ubuntu jammy InRelease                         \u001b[0m\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \u001b[0m\u001b[33m\nGet:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [70.9 kB]\u001b[33m\u001b[33m\nGet:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,809 kB]  \u001b[0m\u001b[33m\u001b[33m\nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]m\nGet:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\u001b[33m\nGet:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \u001b[0m\u001b[33m\nGet:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB][0m\u001b[33m\nGet:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,978 kB]\nHit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \u001b[0m\nGet:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,148 kB]\nGet:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.8 kB]\nGet:20 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]3m\u001b[33m\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,775 kB]3m\nGet:22 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,092 kB][33m\u001b[33m\u001b[33m\nGet:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [82.7 kB]\nFetched 30.5 MB in 2s (12.4 MB/s)[33m                        \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n189 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 189 not upgraded.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torchaudio\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:53:54.097869Z","iopub.execute_input":"2025-04-05T19:53:54.098184Z","iopub.status.idle":"2025-04-05T19:54:01.608192Z","shell.execute_reply.started":"2025-04-05T19:53:54.098155Z","shell.execute_reply":"2025-04-05T19:54:01.607510Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loaded the finetuned deberta model \nThe deberta large model was finetuned on the provided dataset by shl.","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/input/deberta-v3-large-700epoch3best\"  # Replace with your path\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:54:31.275798Z","iopub.execute_input":"2025-04-05T19:54:31.276276Z","iopub.status.idle":"2025-04-05T19:54:50.713282Z","shell.execute_reply.started":"2025-04-05T19:54:31.276248Z","shell.execute_reply":"2025-04-05T19:54:50.712478Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# used whisper for trancribing the input audio\n","metadata":{}},{"cell_type":"code","source":"import whisper\n\n# Load Whisper model (small or medium, depending on GPU)\nasr_model = whisper.load_model(\"medium\")  # or \"small\" if GPU is limited\n\n# Transcribe audio\ndef transcribe(audio_path):\n    result = asr_model.transcribe(audio_path)\n    return result[\"text\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:51:35.436454Z","iopub.execute_input":"2025-04-05T19:51:35.436980Z","iopub.status.idle":"2025-04-05T19:52:20.166096Z","shell.execute_reply.started":"2025-04-05T19:51:35.436936Z","shell.execute_reply":"2025-04-05T19:52:20.165362Z"}},"outputs":[{"name":"stderr","text":"100%|█████████████████████████████████████| 1.42G/1.42G [00:22<00:00, 69.0MiB/s]\n/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# used the finetunned model for label prediction","metadata":{}},{"cell_type":"code","source":"id_to_label = {\n    0: '1.0',\n    1: '1.5',\n    2: '2.0',\n    3: '2.5',\n    4: '3.0',\n    5: '3.5',\n    6: '4.0',\n    7: '4.5',\n    8: '5.0'\n}\n\ndef predict_label(text):\n    try:\n        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n        with torch.no_grad():\n            outputs = model(**inputs)\n            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n            predicted_class = torch.argmax(probs, dim=1).item()\n        mapped_label = id_to_label.get(predicted_class, \"invalid audio\")\n        return mapped_label, probs.tolist()\n    except Exception as e:\n        return \"invalid audio\", []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:10:08.658613Z","iopub.execute_input":"2025-04-05T20:10:08.658999Z","iopub.status.idle":"2025-04-05T20:10:08.665251Z","shell.execute_reply.started":"2025-04-05T20:10:08.658954Z","shell.execute_reply":"2025-04-05T20:10:08.664451Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# full pipeline","metadata":{}},{"cell_type":"code","source":"def audio_to_label(audio_path):\n    transcription = transcribe(audio_path)\n    print(\"Transcription:\", transcription)\n\n    label, probs = predict_label(transcription)\n    print(\"Predicted Label:\", label)\n    print(\"Confidence Scores:\", probs)\n    return label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:11:02.433559Z","iopub.execute_input":"2025-04-05T20:11:02.433920Z","iopub.status.idle":"2025-04-05T20:11:02.438236Z","shell.execute_reply.started":"2025-04-05T20:11:02.433891Z","shell.execute_reply":"2025-04-05T20:11:02.437355Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# test case\n","metadata":{}},{"cell_type":"code","source":"audio_path = \"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1008.wav\"\npredicted_label = audio_to_label(audio_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T20:11:05.305642Z","iopub.execute_input":"2025-04-05T20:11:05.306026Z","iopub.status.idle":"2025-04-05T20:11:11.319626Z","shell.execute_reply.started":"2025-04-05T20:11:05.305998Z","shell.execute_reply":"2025-04-05T20:11:11.318749Z"}},"outputs":[{"name":"stdout","text":"Transcription:  The school playground is lively and filled with colorful equipment like swings and slides. Children engage in various games like dodgeball or soccer. It's normally filled with laughter and chatters in the air. It's normally accompanied with sounds of swings, squeaking and balls bouncing. It's a dynamic environment where friendships are formed and memories are made. Those are experiences from the school playground and scenes you could find on the school playground.\nPredicted Label: 4.0\nConfidence Scores: [[0.011450857855379581, 0.010414010845124722, 0.0378461591899395, 0.026868218556046486, 0.08004546910524368, 0.020012935623526573, 0.3226325511932373, 0.19212931394577026, 0.29860052466392517]]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}